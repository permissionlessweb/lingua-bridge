# LinguaBridge Akash Network Deployment
#
# Two-tier architecture: unified inference (GPU), bot (CPU).
# The unified inference service provides both text and voice translation on a single GPU.
#
# Before deploying:
# 1. Generate admin keys: cargo run -p admin-cli -- keygen
# 2. Replace <YOUR_ADMIN_PUBLIC_KEY> with contents of admin.pub
# 3. Build and push Docker images to GHCR with explicit version tags
# 4. Update GHCR credentials below (username + PAT with read:packages scope)
# 5. Update image tags to match your pushed versions
#
# After deployment:
# 1. Note the assigned URIs from Akash
# 2. Provision the bot:
#    linguabridge-admin provision --bot-url https://<akash-uri>:9999 \
#      --discord-token "token" --admin-key admin.key

version: "2.0"

services:
  # Unified inference service (GPU required)
  # Provides both REST API (text translation) and WebSocket (voice translation)
  # Base: nvidia/cuda:12.4.1-runtime-ubuntu22.04, Python 3.11
  # Models: TranslateGemma (translation), Distil-Whisper (STT), CosyVoice (TTS)
  inference:
    image: ghcr.io/permissionlessweb/linguabridge-unified:v0.2.0
    credentials:
      host: ghcr.io
      username: <GHCR_USERNAME>
      password: <GHCR_PAT>
    env:
      - "DEVICE=cuda"
      - "TORCH_DTYPE=bfloat16"
      - "TRANSLATEGEMMA_MODEL=google/translategemma-4b-it"
      - "STT_MODEL=distil-large-v3"
      - "TTS_MODEL=CosyVoice2-0.5B"
      - "ENABLE_STT=true"
      - "ENABLE_TTS=true"
      - "ENABLE_DIARIZATION=false"
      - "HF_TOKEN=<HF_TOKEN>"
      - "HOST=0.0.0.0"
      - "PORT=8000"
      - "PYTHONUNBUFFERED=1"
      - "TRANSFORMERS_CACHE=/root/.cache/huggingface"
      - "HF_HOME=/root/.cache/huggingface"
    expose:
      - port: 8000
        as: 8000
        to:
          - service: bot
    params:
      storage:
        data:
          mount: /root/.cache
          readOnly: false

  # LinguaBridge Discord bot and web server (CPU only)
  # Base: debian:trixie-slim, Rust binary
  bot:
    image: ghcr.io/permissionlessweb/linguabridge-bot:v0.1.0
    credentials:
      host: ghcr.io
      username: <GHCR_USERNAME>
      password: <GHCR_PAT>
    dependencies:
      - service: inference
    env:
      # Admin provisioning (public key only - safe to expose)
      - "LINGUABRIDGE_ADMIN__PUBLIC_KEY=<YOUR_ADMIN_PUBLIC_KEY>"
      - "LINGUABRIDGE_ADMIN__PORT=9999"
      - "LINGUABRIDGE_ADMIN__HOST=0.0.0.0"
      # Internal service URLs (Akash DNS resolution)
      # Both text and voice translation now use the same inference service
      - "LINGUABRIDGE_INFERENCE__URL=http://inference:8000"
      - "LINGUABRIDGE_VOICE__URL=ws://inference:8000/voice"
      - "LINGUABRIDGE_VOICE__ENABLE_TTS_PLAYBACK=false"
      - "LINGUABRIDGE_VOICE__DEFAULT_TARGET_LANGUAGE=en"
      # Web server
      - "LINGUABRIDGE_WEB__HOST=0.0.0.0"
      - "LINGUABRIDGE_WEB__PORT=3000"
      - "LINGUABRIDGE_WEB__PUBLIC_URL=https://your-deployment.akash.network"
      # Database (persistent storage)
      - "LINGUABRIDGE_DATABASE__URL=sqlite:///data/linguabridge.db?mode=rwc"
      - "RUST_LOG=linguabridge=info,tower_http=info"
    expose:
      # Web interface - publicly accessible
      - port: 3000
        as: 80
        to:
          - global: true
      # Admin provisioning endpoint - signed requests only
      - port: 9999
        as: 9999
        to:
          - global: true
    params:
      storage:
        data:
          mount: /data
          readOnly: false

profiles:
  compute:
    inference:
      resources:
        cpu:
          units: 8
        memory:
          size: 128Gi
        storage:
          - size: 50Gi
          - name: data
            size: 200Gi
            attributes:
              persistent: true
              class: beta3
        gpu:
          units: 2
          attributes:
            vendor:
              nvidia:
                - model: a100
                - model: h100
    bot:
      resources:
        cpu:
          units: 1
        memory:
          size: 512Mi
        storage:
          - size: 1Gi
          - name: data
            size: 1Gi
            attributes:
              persistent: true
              class: beta3
  placement:
    dcloud:
      pricing:
        inference:
          denom: uakt
          amount: 1000000
        bot:
          denom: uakt
          amount: 50000
deployment:
  inference:
    dcloud:
      profile: inference
      count: 1
  bot:
    dcloud:
      profile: bot
      count: 1
